{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Read the CSV file\n",
    "# 2. In the content field, do the following:\n",
    "# - Tokenize and lower-case the text (end result should be an array of tokens where each token is a lexical unit or a punctuation). For example, “He said: ‘Don’t go there!’” => (he, said, :, ‘, don’t, go, there, !, ‘)\n",
    "# - Remove consecutive spaces and new lines\n",
    "# - Find and replace URLs with <URL>\n",
    "# - Find and replace dates with <DATE>\n",
    "# - Find and replace numbers with <NUM>\n",
    "# 3. For the metadata fields:\n",
    "# - Fill all empty fields with a placeholder NULL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer, ToktokTokenizer\n",
    "from collections import Counter \n",
    "import itertools\n",
    "import matplotlib as plt\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readUrl(url):\n",
    "    data = pd.read_csv(url)\n",
    "    return data\n",
    "\n",
    "def swapUrl(line):\n",
    "    urlPattern = r'((http|https)\\:\\/\\/)?[a-zA-Z0-9\\.\\/\\?\\:@\\-_=#]+\\.([a-zA-Z]){2,6}([a-zA-Z0-9\\.\\&\\/\\?\\:@\\-_=#])*'\n",
    "    line = re.sub(urlPattern,' <URL> ', line)\n",
    "    return line\n",
    "def swapDates(line):\n",
    "    re1 = r'[\\d]{1,2}(th)? [adfjmnos]\\w*[,]?[.]? ([\\d]{2,4})?'\n",
    "    re2 = r'[adfjmnos]\\w*[,]?[.]? [\\d]{1,2}(th)?[,]? ([\\d]{2,4})?'\n",
    "    re3 = r'[adfjmnos]\\w* [\\d]{1,2}[,]?[.]?([\\d]{2,4})?'\n",
    "    re4 = r'[\\d]{1,2}-[\\d]{1,2}-[\\d]{2,4}'\n",
    "    re5 = r'[\\d]{1,2}/[\\d]{1,2}/[\\d]{2,4}'\n",
    "    re6 = r'[\\d]{1,2} [\\d]{1,2} [\\d]{2,4}'\n",
    "    re7 = r'[\\d].{1,2}.[\\d]{1,2}.[\\d]{2,4}'\n",
    "    finReg = [re1, re2, re3, re4, re5, re6, re7]\n",
    "    for reg in finReg:\n",
    "        line = re.sub(reg, ' <DATE> ', line)\n",
    "    return line\n",
    "def swapNumb(line):\n",
    "    pattern = r'[\\d]+[,]?([\\d]+)?'\n",
    "    line = re.sub(pattern, ' <NUM> ', line)\n",
    "    return line\n",
    "dateCount = 0\n",
    "numbCount = 0\n",
    "urlCount = 0\n",
    "def counter(data):\n",
    "    countDict = {'DATE': 0, 'URL': 0, 'NUM': 0}\n",
    "    for line in data:\n",
    "        for key in countDict:\n",
    "            countDict[key] += line.count('<'+str(key) + '>') \n",
    "    return countDict\n",
    "def wordCount(content, k):\n",
    "    flatten = list(itertools.chain.from_iterable(content))\n",
    "    punct = re.compile(r'\\W')\n",
    "    filtered = filter(lambda i: not punct.search(i), flatten)\n",
    "    counter = Counter(filtered)\n",
    "    most_freq = counter.most_common(k)\n",
    "    return most_freq\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "a bytes-like object is required, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-9ba40fb56951>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mfwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsvfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcounted\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mfwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m#rawData.to_csv(r'/Users/oyvinkm/Documents/DATALOGI/DataScience/out.csv', encoding='utf-8', index=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: a bytes-like object is required, not 'str'"
     ]
    }
   ],
   "source": [
    "rawData = readUrl('https://raw.githubusercontent.com/several27/FakeNewsCorpus/master/news_sample.csv')\n",
    "token = TweetTokenizer()\n",
    "tokenizedList = []\n",
    "for line in rawData['content']:\n",
    "    line = line.lower()\n",
    "    pattern = re.compile(r'\\s+')\n",
    "    line = re.sub(pattern, ' ', line)\n",
    "    line = line.rstrip('\\n')\n",
    "    line = swapUrl(line)\n",
    "    line = swapDates(line)\n",
    "    line = swapNumb(line)\n",
    "    tokenizedList.append(token.tokenize(line))\n",
    "rawData['content'] = tokenizedList\n",
    "metaList = []\n",
    "for line in rawData['meta_keywords']:\n",
    "    if (line ==  \"['']\"):\n",
    "        metaList.append(np.nan)\n",
    "    else: \n",
    "        metaList.append(line)\n",
    "rawData['meta_keywords'] = metaList\n",
    "count = counter(rawData['content'])\n",
    "counted = wordCount(rawData['content'], 1000)\n",
    "with open('words.csv', 'wb') as csvfile:\n",
    "    fwriter = csv.writer(csvfile)\n",
    "    for x in counted:\n",
    "        fwriter.writerow(x)\n",
    "   \n",
    "#rawData.to_csv(r'/Users/oyvinkm/Documents/DATALOGI/DataScience/out.csv', encoding='utf-8', index=False)\n",
    "#rawData\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " <URL> \n",
      "['a', 'c', 'jsd', 'd', 'a', 'a', 'c']\n",
      "[('a', 3), ('c', 2)]\n",
      "{'DATE': 4, 'URL': 3, 'NUM': 4}\n"
     ]
    }
   ],
   "source": [
    "test = swapUrl('https://www.youtube.com/watch?v=cJymBJ_5iUg')\n",
    "print(test)\n",
    "dateTest = []\n",
    "dateTest.append(swapDates('17/11/1996'))\n",
    "dateTest.append(swapDates('17 november 1996'))\n",
    "dateTest.append(swapDates('17-11-1996'))\n",
    "dateTest.append(swapDates('17 jun 2018'))\n",
    "dateTest.append(swapDates('nov 17 1996'))\n",
    "dateTest.append(swapDates('january, 15 '))\n",
    "dateTest.append(swapDates('17 november '))\n",
    "dateTest.append(swapDates('jan. 15 2018'))\n",
    "dateTest.append(swapDates('jan 31.2018'))\n",
    "dateTest.append(swapNumb('halla 123 hall 732,189'))\n",
    "t = ['This is a <DATE> and <URL> <URL> comes up <NUM> <NUM> <NUM>', '<DATE> as <DATE> asd <DATE> asd <URL> <NUM>']\n",
    "dictio = counter(t)\n",
    "t = [['a', 'c', 'jsd'], ['d', 'a', 'a', 'c']]\n",
    "print(wordCount(t, 2))\n",
    "print(dictio)\n",
    "#for elm in dateTest:\n",
    "    #print(elm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

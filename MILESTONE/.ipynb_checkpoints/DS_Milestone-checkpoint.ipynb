{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Project group 35 - Marcus Braunschweig Andersen, Ã˜yvin Moxness Konglevoll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import re\n",
    "from collections import Counter \n",
    "import itertools\n",
    "import matplotlib as plt\n",
    "import csv\n",
    "import string\n",
    "import psycopg2\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"datascience.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design\n",
    "For the design of our database we choose to split the dataset and fragment it. Instead of having long fields containing alot of information we create IDs to represent; 'domain', 'article', 'type', 'meta_keyword', 'time' and 'author'. All of these are then joined in a table which enables us to see which article the respective IDs are linked to. The reason for doing this is since alot of information, such as 'domain', 'timestamp' and 'type', occur many times in the dataset. Therefore we are able to begin with for instance evaluating a type and then the responding articles without having to run through all the articles to find the right type.\n",
    "\n",
    "Using this structure also allows us to associate multiple data ID's with each ID, while still having these data separate. As an example some of the articles in our database have multiple authors, and this we represent by having an entry in the 'writers' relation pairing each of the writers to the 'articleID'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demonstrate that we have a working database, we will use the handed out function for executing SQL-queris in python. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed query and closed connection.\n",
      "[(979937,)]\n",
      "Executed query and closed connection.\n",
      "[(979937,)]\n",
      "Executed query and closed connection.\n",
      "[(0, 'rumor'), (1, 'hate'), (6, 'unreliable'), (10, 'conspiracy'), (14, 'clickbait'), (15, 'satire'), (27, 'fake'), (42, 'reliable'), (132, 'bias'), (136, 'political'), (351, 'junksci'), (397, 'NULL'), (628, 'unknown')]\n"
     ]
    }
   ],
   "source": [
    "# Function to access the database locally, and execute a query\n",
    "# Make sure to change the username, databse and password\n",
    "def execQuery(query):\n",
    "    try:\n",
    "        connection = psycopg2.connect(user = \"postgres\",\n",
    "                                      password = \"dataScience20\",\n",
    "                                      host = \"localhost\",\n",
    "                                      port = \"5432\",\n",
    "                                      database = \"fakenews\")\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(query)\n",
    "        record = cursor.fetchall()\n",
    "        return record\n",
    "    except (Exception, psycopg2.Error) as error :\n",
    "        connection = False\n",
    "        print (\"Error while connecting to PostgreSQL\", error)\n",
    "    finally:\n",
    "        if(connection):\n",
    "            cursor.close()\n",
    "            connection.close()\n",
    "            print(\"Executed query and closed connection.\")\n",
    "            \n",
    "numberOfArticles = execQuery(\"\"\"SELECT count(articleid)\n",
    "                                FROM articles;\"\"\")\n",
    "print(numberOfArticles)\n",
    "\n",
    "articleDomainsCount = execQuery(\"\"\"SELECT count(domainID)\n",
    "                                   FROM articleDomains;\"\"\")\n",
    "print(articleDomainsCount)\n",
    "\n",
    "differentTypes = execQuery(\"\"\"SELECT *\n",
    "                              FROM Typer; \"\"\")\n",
    "print(differentTypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above, we have a database containing 979937 articles, and it supports simple queries, such as seeing all the different types all of the articles have. We used the '1mio-raw.csv' file, but in the cleaning process discarded all articles with faults in the articleID "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1\n",
    "### Relational algebra\n",
    "\\begin{align*}\n",
    "    A &:= Articles\\\\\n",
    "    B &:= DomainArticles\\\\\n",
    "    D &:= \\pi_{articleId}(A \\bowtie_{Timestamps_{timstamp} \\geq '2018-01-15 00:00:00.000000'}Timestamps) \\\\\n",
    "    C &:= \\pi_{DomainID}(D \\bowtie B)\\\\\n",
    "    E &:= \\pi_{typeID}(\\sigma_{type='reliable'}(Typer)) \\\\\n",
    "    F &:= \\pi_{Domain,DomainId}(\\sigma_{Domains_{typeID='E'}})(Domains) \\\\\n",
    "\\end{align*}\n",
    "The domains of news articles scraped at or after January 15, 2018, can now be found with\n",
    "\\begin{align*}\n",
    "\\Pi_{Domain}(F \\bowtie  C)\n",
    "\\end{align*}\n",
    "\n",
    "### SQL\n",
    "``` mysql\n",
    "SELECT DISTINCT domainet FROM domains \n",
    "WHERE typeid IN \n",
    "(SELECT typeid FROM Typer WHERE typen = 'reliable') AND \n",
    "domainID IN (SELECT domainID FROM articleDomains WHERE articleID IN \n",
    "(SELECT articleID FROM articles WHERE scrapedid IN \n",
    "(SELECT timeid FROM timestamps WHERE timstamp >= '2018-01-15 00:00:00.000000')));\n",
    "```\n",
    "Running the SQL-query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed query and closed connection.\n",
      "[('christianpost.com',), ('consortiumnews.com',), ('nutritionfacts.org',)]\n"
     ]
    }
   ],
   "source": [
    "domains = execQuery(\"\"\"SELECT DISTINCT domainet FROM domains \n",
    "WHERE typeid IN \n",
    "(SELECT typeid FROM Typer WHERE typen = 'reliable') AND \n",
    "domainID IN (SELECT domainID FROM articleDomains WHERE articleID IN \n",
    "(SELECT articleID FROM articles WHERE scrapedid IN \n",
    "(SELECT timeid FROM timestamps WHERE timstamp >= '2018-01-15 00:00:00.000000')));\"\"\")\n",
    "print(domains)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2\n",
    "### Extended relational algebra\n",
    "\\begin{align*}\n",
    "    A &:= Articles\\\\\n",
    "    B &:= DomainArticles\\\\\n",
    "    W &:= Writers\\\\\n",
    "    X &:= \\pi_{typeID}(\\sigma_{type='fake'}(Typer))\\\\\n",
    "    D &:= \\pi_{DomainId}(\\sigma_{Domains_{typeID='X'}})Domains)\\\\\n",
    "    E &:= \\pi_{ArticleID}(B \\bowtie D) \\\\\n",
    "    G &:= \\gamma_{authorId, count(articleID)\\rightarrow countA}(W \\bowtie E) \\\\\n",
    "    H &:= G_{Max(countA)} \\\\\n",
    "    I &:= \\Pi_{authorId}(\\sigma_{countA \\geq H}(G)) \\\\\n",
    "\\end{align*}\n",
    "\n",
    "The name(s) of the most prolific author(s) of fake news articles can now be found with:\n",
    "\\begin{align*}\\Pi_{authorName}(Authors \\bowtie I)\\end{align*}\n",
    "\n",
    "### SQL\n",
    "``` mysql\n",
    "Select author_name from authors where authorID in (Select authorID from (Select authorID, count(articleid)\n",
    "\tFrom writers\n",
    "\tWhere articleID in (SELECT ARTICLEID as X FROM articledomains WHERE DOMAINID IN \n",
    "\t\t\t(SELECT DOMAINID FROM DOMAINs WHERE TYPEID = \n",
    "\t\t\t\t(SELECT TYPEID FROM TYPER WHERE TYPEN = 'fake'))) AND authorID > 0\n",
    "\tGroup by authorID) as mycount\n",
    "\twhere count = (Select max(count) from (Select authorID, count(articleid)\n",
    "\tFrom writers\n",
    "\tWhere articleID in (SELECT ARTICLEID as X FROM articledomains WHERE DOMAINID IN \n",
    "\t\t\t(SELECT DOMAINID FROM DOMAINs WHERE TYPEID = \n",
    "\t\t\t\t(SELECT TYPEID FROM TYPER WHERE TYPEN = 'fake'))) AND authorID > 0\n",
    "\tGroup by authorID) as mycount));\n",
    "```\n",
    "Running the SQL query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed query and closed connection.\n",
      "[('john rolls',)]\n"
     ]
    }
   ],
   "source": [
    "authors = execQuery(\"\"\"Select author_name from authors where authorID in (Select authorID from (Select authorID, count(articleid)\n",
    "\tFrom writers\n",
    "\tWhere articleID in (SELECT ARTICLEID as X FROM articledomains WHERE DOMAINID IN \n",
    "\t\t\t(SELECT DOMAINID FROM DOMAINs WHERE TYPEID = \n",
    "\t\t\t\t(SELECT TYPEID FROM TYPER WHERE TYPEN = 'fake'))) AND authorID > 0\n",
    "\tGroup by authorID) as mycount\n",
    "\twhere count = (Select max(count) from (Select authorID, count(articleid)\n",
    "\tFrom writers\n",
    "\tWhere articleID in (SELECT ARTICLEID as X FROM articledomains WHERE DOMAINID IN \n",
    "\t\t\t(SELECT DOMAINID FROM DOMAINs WHERE TYPEID = \n",
    "\t\t\t\t(SELECT TYPEID FROM TYPER WHERE TYPEN = 'fake'))) AND authorID > 0\n",
    "\tGroup by authorID) as mycount));\"\"\")\n",
    "print(authors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3\n",
    "We failed to write out this query succesfully, but this our attempt. It finds article ID's who share meta_keywordID's, and also shows the meta_keywordID they share\n",
    "### SQL\n",
    "``` mysql\n",
    "WITH tags_small AS (SELECT * FROM articlemeta_keywords WHERE articleid <= 500 and meta_keywordID > 0),\n",
    "     articles_small AS (SELECT DISTINCT articleid FROM tags_small)\n",
    "\tSELECT a1.meta_keywordID, a1.articleID AS a1, a2.articleID AS a2 FROM tags_small a1 JOIN tags_small a2 ON a1.articleID <> a2.articleID and a1.meta_keywordID = a2.meta_keywordID;\n",
    "```\n",
    "Running this query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed query and closed connection.\n",
      "[(12, 19, 20), (13, 19, 20), (14, 19, 20), (15, 19, 20), (16, 19, 20), (17, 19, 20), (18, 19, 20), (19, 19, 20), (12, 20, 19), (13, 20, 19), (14, 20, 19), (15, 20, 19), (16, 20, 19), (17, 20, 19), (18, 20, 19), (19, 20, 19), (27, 33, 99), (27, 33, 98), (37, 73, 138), (38, 73, 483), (38, 73, 138), (27, 98, 99), (27, 98, 33), (27, 99, 98), (27, 99, 33), (60, 109, 167), (61, 109, 167), (37, 138, 73), (38, 138, 483), (38, 138, 73), (64, 138, 483), (38, 483, 138), (38, 483, 73), (64, 483, 138), (60, 167, 109), (61, 167, 109)]\n"
     ]
    }
   ],
   "source": [
    "set_equi_join = execQuery(\"\"\"WITH tags_small AS (SELECT * FROM articlemeta_keywords WHERE articleid <= 500 and meta_keywordID > 0),\n",
    "     articles_small AS (SELECT DISTINCT articleid FROM tags_small)\n",
    "\tSELECT a1.meta_keywordID, a1.articleID AS a1, a2.articleID AS a2 FROM tags_small a1 JOIN tags_small a2 ON a1.articleID <> a2.articleID and a1.meta_keywordID = a2.meta_keywordID;\"\"\")\n",
    "print(set_equi_join)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4\n",
    "## Query 1:\n",
    "Finding the fraction of 'fake news' articles, which have no listed author(s).\n",
    "\n",
    "### SQL:\n",
    "``` mysql\n",
    "With fakeID as (SELECT typeID FROM Typer WHERE typen='fake'), \n",
    "fakeDomains as (SELECT domainID FROM domains WHERE typeID = (SELECT * FROM fakeID)), \n",
    "noAuthorID as (SELECT authorID FROM authors WHERE author_name = 'nan'),\n",
    "fakeArticles as (SELECT articleID FROM articleDomains WHERE domainID IN (SELECT * from fakeDomains)),\n",
    "noAuthorcount as (SELECT count(articleID) FROM writers WHERE articleID IN (SELECT * from fakeArticles) AND writers.authorID = (SELECT authorID FROM noAuthorID))\n",
    "SELECT count(articleID) as totalFake, noAuthorCount.count as fakeNoAuthor\n",
    "From fakeArticles, noAuthorcount\n",
    "GROUP BY noAuthorCount.count;\n",
    "```\n",
    "Running the query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed query and closed connection.\n",
      "[(123788, 39466)]\n",
      "Ratio:  0.31881927165799595\n"
     ]
    }
   ],
   "source": [
    "fakeNoAuthors = execQuery(\"\"\"With fakeID as (SELECT typeID FROM Typer WHERE typen='fake'), \n",
    "fakeDomains as (SELECT domainID FROM domains WHERE typeID = (SELECT * FROM fakeID)), \n",
    "noAuthorID as (SELECT authorID FROM authors WHERE author_name = 'nan'),\n",
    "fakeArticles as (SELECT articleID FROM articleDomains WHERE domainID IN (SELECT * from fakeDomains)),\n",
    "noAuthorcount as (SELECT count(articleID) FROM writers WHERE articleID IN (SELECT * from fakeArticles) AND writers.authorID = (SELECT authorID FROM noAuthorID))\n",
    "SELECT count(articleID) as totalFake, noAuthorCount.count as fakeNoAuthor\n",
    "From fakeArticles, noAuthorcount\n",
    "GROUP BY noAuthorCount.count;\n",
    "\"\"\")\n",
    "print(fakeNoAuthors)\n",
    "print(\"Ratio: \", fakeNoAuthors[0][1]/fakeNoAuthors[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query 2:\n",
    "Finding which domain has published the highest amount of 'reliable' articles.\n",
    "\n",
    "### SQL:\n",
    "``` mysql\n",
    "WITH reliableID as (SELECT typeID FROM Typer WHERE typen='reliable'),\n",
    "reliableDomains as (SELECT domainID FROM Domains WHERE typeID = (SELECT * from reliableID)),\n",
    "reliableCount as (SELECT domainID, count(articleID) as count FROM articleDomains WHERE domainID IN (SELECT * FROM reliableDomains) GROUP BY domainID),\n",
    "reliableIDMax as (SELECT domainID, count FROM reliableCount WHERE count = (SELECT MAX(count) FROM reliableCount))\n",
    "SELECT domainet\n",
    "from domains\n",
    "where domainID = (SELECT domainID FROM reliableIDMax);\n",
    "```\n",
    "Running the query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed query and closed connection.\n",
      "Domain published the highest amount of reliable articles: christianpost.com\n"
     ]
    }
   ],
   "source": [
    "mostReliablesDomain = execQuery(\"\"\"WITH reliableID as (SELECT typeID FROM Typer WHERE typen='reliable'),\n",
    "reliableDomains as (SELECT domainID FROM Domains WHERE typeID = (SELECT * from reliableID)),\n",
    "reliableCount as (SELECT domainID, count(articleID) as count FROM articleDomains WHERE domainID IN (SELECT * FROM reliableDomains) GROUP BY domainID),\n",
    "reliableIDMax as (SELECT domainID, count FROM reliableCount WHERE count = (SELECT MAX(count) FROM reliableCount))\n",
    "SELECT domainet\n",
    "from domains\n",
    "where domainID = (SELECT domainID FROM reliableIDMax);\"\"\")\n",
    "print(\"Domain published the highest amount of reliable articles:\", mostReliablesDomain[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query 3\n",
    "Finding the most frequent tag in all 'fake news' articles.\n",
    "\n",
    "### SQL:\n",
    "``` mysql\n",
    "With fakeID as (SELECT typeID FROM Typer WHERE typen='fake'), \n",
    "fakeDomains as (SELECT domainID FROM domains WHERE typeID = (SELECT * FROM fakeID)), \n",
    "fakeArticles as (SELECT articleID FROM articleDomains WHERE domainID IN (SELECT * from fakeDomains)),\n",
    "tagCount as (SELECT count(articleID), tagID FROM articleTags WHERE tagID > 0 AND articleID IN (SELECT * FROM fakeArticles) GROUP BY tagID),\n",
    "tagCountMax as (SELECT tagID, count FROM tagCount WHERE count = (SELECT MAX(count) FROM tagCount))\n",
    "SELECT tag\n",
    "FROM tags\n",
    "WHERE tagID = (SELECT tagID from tagCountMAX);\n",
    "```\n",
    "Running the query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed query and closed connection.\n",
      "Most frequent tag in 'fake news' articles:  united states\n"
     ]
    }
   ],
   "source": [
    "mostFrequentTagInFakeNews = execQuery(\"\"\"With fakeID as (SELECT typeID FROM Typer WHERE typen='fake'), \n",
    "fakeDomains as (SELECT domainID FROM domains WHERE typeID = (SELECT * FROM fakeID)), \n",
    "fakeArticles as (SELECT articleID FROM articleDomains WHERE domainID IN (SELECT * from fakeDomains)),\n",
    "tagCount as (SELECT count(articleID), tagID FROM articleTags WHERE tagID > 0 AND articleID IN (SELECT * FROM fakeArticles) GROUP BY tagID),\n",
    "tagCountMax as (SELECT tagID, count FROM tagCount WHERE count = (SELECT MAX(count) FROM tagCount))\n",
    "SELECT tag\n",
    "FROM tags\n",
    "WHERE tagID = (SELECT tagID from tagCountMAX);\"\"\")\n",
    "print(\"Most frequent tag in 'fake news' articles: \", mostFrequentTagInFakeNews[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 5\n",
    "## 5.1 Spider\n",
    "In order to scrape wikinews for articles we have used the scrapy framework. Below is the code for our scrapy.Spider. The code uses two parse function, 'parse': extracts the links of articles from each page of listed articles corresponding to our group number. A call to 'parse_article' is the made for each link found, and then 'parse' is called recursively on the next page link until there are no more pages. \n",
    "'parse_article' extracts the data into these fields: 'url', 'title', 'date' and 'content', by using the XPath we found in the structure of an article page.\n",
    "\n",
    "When creating the spider we spent some time understanding how the scrapy framework worked, and also understandig how to use HTML and XML properly in our spider as none of use had any prior knowledge with these. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##CODE WILL NOT EXECUTE\n",
    "def parse(self,response):\n",
    "        for link in response.xpath('/html/body/div[3]/div[3]/div[4]/div[2]/div[2]/div/div/div/ul/li/a/@href').re(r'\\/wiki\\/[MNOPRSTUW]\\S*'):\n",
    "            link = response.urljoin(link)\n",
    "            yield scrapy.Request(link, callback=self.parse_article)\n",
    "        #print(links)\n",
    "        \n",
    "        next_page = response.xpath('/html/body/div[3]/div[3]/div[4]/div[2]/div[2]/a[2]/@href').get()\n",
    "        if next_page is not None:\n",
    "            next_page = response.urljoin(next_page)\n",
    "            yield scrapy.Request(next_page, callback=self.parse)\n",
    "        pass\n",
    "    \n",
    "    def parse_article(self, response):\n",
    "        url = response.url\n",
    "        title = response.xpath('//*[@id=\"firstHeading\"]/text()').get()\n",
    "        date = response.xpath('/html/body/div[3]/div[3]/div[4]/div/p[1]/strong/text()').get()\n",
    "        raw_text = response.xpath('/html/body/div[3]/div[3]/div[4]/div/p').extract() \n",
    "        yield {\n",
    "                \"url\" : url,\n",
    "                \"title\": title,\n",
    "                \"date\": date,\n",
    "                \"content\": raw_text}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In total we get a dataset with 3595 rows each containing the four fields: 'url', 'title', 'date' and 'content'. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

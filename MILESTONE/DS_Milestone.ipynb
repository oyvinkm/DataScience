{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Project group 35 - Marcus Braunschweig Andersen, Ã˜yvin Moxness Konglevoll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import re\n",
    "from collections import Counter \n",
    "import itertools\n",
    "import matplotlib as plt\n",
    "import csv\n",
    "import string\n",
    "import psycopg2\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"datascience.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demonstrate that we have a working database, we will use the handed out function for executing SQL-queris in python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed query and closed connection.\n",
      "[(979937,)]\n",
      "Executed query and closed connection.\n",
      "[(979937,)]\n",
      "Executed query and closed connection.\n",
      "[(0, 'rumor'), (1, 'hate'), (6, 'unreliable'), (10, 'conspiracy'), (14, 'clickbait'), (15, 'satire'), (27, 'fake'), (42, 'reliable'), (132, 'bias'), (136, 'political'), (351, 'junksci'), (397, 'NULL'), (628, 'unknown')]\n"
     ]
    }
   ],
   "source": [
    "# Function to access the database locally, and execute a query\n",
    "# Make sure to change the username, databse and password\n",
    "def execQuery(query):\n",
    "    try:\n",
    "        connection = psycopg2.connect(user = \"postgres\",\n",
    "                                      password = \"dataScience20\",\n",
    "                                      host = \"localhost\",\n",
    "                                      port = \"5432\",\n",
    "                                      database = \"fakenews\")\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(query)\n",
    "        record = cursor.fetchall()\n",
    "        return record\n",
    "    except (Exception, psycopg2.Error) as error :\n",
    "        connection = False\n",
    "        print (\"Error while connecting to PostgreSQL\", error)\n",
    "    finally:\n",
    "        if(connection):\n",
    "            cursor.close()\n",
    "            connection.close()\n",
    "            print(\"Executed query and closed connection.\")\n",
    "            \n",
    "numberOfArticles = execQuery(\"\"\"SELECT count(articleid)\n",
    "                                FROM articles;\"\"\")\n",
    "print(numberOfArticles)\n",
    "\n",
    "articleDomainsCount = execQuery(\"\"\"SELECT count(domainID)\n",
    "                                   FROM articleDomains;\"\"\")\n",
    "print(articleDomainsCount)\n",
    "\n",
    "differentTypes = execQuery(\"\"\"SELECT *\n",
    "                              FROM Typer; \"\"\")\n",
    "print(differentTypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above, we have a database containing 979937 articles, and it supports simple queries, such as seeing all the different types all of the articles have. We used the '1mio-raw.csv' file, but in the cleaning process discarded all articles with faults in the articleID "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1\n",
    "### Relational algebra\n",
    "\\begin{align*}\n",
    "    A &:= Articles\\\\\n",
    "    B &:= DomainArticles\\\\\n",
    "    D &:= \\pi_{articleId}(A \\bowtie_{Timestamps_{timstamp} \\geq '2018-01-15 00:00:00.000000'}Timestamps) \\\\\n",
    "    C &:= \\pi_{DomainID}(D \\bowtie B)\\\\\n",
    "    E &:= \\pi_{typeID}(\\sigma_{type='reliable'}(Typer)) \\\\\n",
    "    F &:= \\pi_{Domain,DomainId}(\\sigma_{Domains_{typeID='E'}})(Domains) \\\\\n",
    "\\end{align*}\n",
    "The domains of news articles scraped at or after January 15, 2018, can now be found with\n",
    "\\begin{align*}\n",
    "\\Pi_{Domain}(F \\bowtie  C)\n",
    "\\end{align*}\n",
    "\n",
    "### SQL\n",
    "``` mysql\n",
    "SELECT DISTINCT domainet FROM domains \n",
    "WHERE typeid IN \n",
    "(SELECT typeid FROM Typer WHERE typen = 'reliable') AND \n",
    "domainID IN (SELECT domainID FROM articleDomains WHERE articleID IN \n",
    "(SELECT articleID FROM articles WHERE scrapedid IN \n",
    "(SELECT timeid FROM timestamps WHERE timstamp >= '2018-01-15 00:00:00.000000')));\n",
    "```\n",
    "Running the SQL-query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed query and closed connection.\n",
      "[('christianpost.com',), ('consortiumnews.com',), ('nutritionfacts.org',)]\n"
     ]
    }
   ],
   "source": [
    "domains = execQuery(\"\"\"SELECT DISTINCT domainet FROM domains \n",
    "WHERE typeid IN \n",
    "(SELECT typeid FROM Typer WHERE typen = 'reliable') AND \n",
    "domainID IN (SELECT domainID FROM articleDomains WHERE articleID IN \n",
    "(SELECT articleID FROM articles WHERE scrapedid IN \n",
    "(SELECT timeid FROM timestamps WHERE timstamp >= '2018-01-15 00:00:00.000000')));\"\"\")\n",
    "print(domains)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2\n",
    "### Extended relational algebra\n",
    "\\begin{align*}\n",
    "    A &:= Articles\\\\\n",
    "    B &:= DomainArticles\\\\\n",
    "    W &:= Writers\\\\\n",
    "    X &:= \\pi_{typeID}(\\sigma_{type='fake'}(Typer))\\\\\n",
    "    D &:= \\pi_{DomainId}(\\sigma_{Domains_{typeID='X'}})Domains)\\\\\n",
    "    E &:= \\pi_{ArticleID}(B \\bowtie D) \\\\\n",
    "    G &:= \\gamma_{authorId, count(articleID)\\rightarrow countA}(W \\bowtie E) \\\\\n",
    "    H &:= G_{Max(countA)} \\\\\n",
    "    I &:= \\Pi_{authorId}(\\sigma_{countA \\geq H}(G)) \\\\\n",
    "\\end{align*}\n",
    "\n",
    "The name(s) of the most prolific author(s) of fake news articles can now be found with:\n",
    "\\begin{align*}\\Pi_{authorName}(Authors \\bowtie I)\\end{align*}\n",
    "\n",
    "### SQL\n",
    "``` mysql\n",
    "Select author_name from authors where authorID in (Select authorID from (Select authorID, count(articleid)\n",
    "\tFrom writers\n",
    "\tWhere articleID in (SELECT ARTICLEID as X FROM articledomains WHERE DOMAINID IN \n",
    "\t\t\t(SELECT DOMAINID FROM DOMAINs WHERE TYPEID = \n",
    "\t\t\t\t(SELECT TYPEID FROM TYPER WHERE TYPEN = 'fake'))) AND authorID > 0\n",
    "\tGroup by authorID) as mycount\n",
    "\twhere count = (Select max(count) from (Select authorID, count(articleid)\n",
    "\tFrom writers\n",
    "\tWhere articleID in (SELECT ARTICLEID as X FROM articledomains WHERE DOMAINID IN \n",
    "\t\t\t(SELECT DOMAINID FROM DOMAINs WHERE TYPEID = \n",
    "\t\t\t\t(SELECT TYPEID FROM TYPER WHERE TYPEN = 'fake'))) AND authorID > 0\n",
    "\tGroup by authorID) as mycount));\n",
    "```\n",
    "Running the SQL query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed query and closed connection.\n",
      "[('john rolls',)]\n"
     ]
    }
   ],
   "source": [
    "authors = execQuery(\"\"\"Select author_name from authors where authorID in (Select authorID from (Select authorID, count(articleid)\n",
    "\tFrom writers\n",
    "\tWhere articleID in (SELECT ARTICLEID as X FROM articledomains WHERE DOMAINID IN \n",
    "\t\t\t(SELECT DOMAINID FROM DOMAINs WHERE TYPEID = \n",
    "\t\t\t\t(SELECT TYPEID FROM TYPER WHERE TYPEN = 'fake'))) AND authorID > 0\n",
    "\tGroup by authorID) as mycount\n",
    "\twhere count = (Select max(count) from (Select authorID, count(articleid)\n",
    "\tFrom writers\n",
    "\tWhere articleID in (SELECT ARTICLEID as X FROM articledomains WHERE DOMAINID IN \n",
    "\t\t\t(SELECT DOMAINID FROM DOMAINs WHERE TYPEID = \n",
    "\t\t\t\t(SELECT TYPEID FROM TYPER WHERE TYPEN = 'fake'))) AND authorID > 0\n",
    "\tGroup by authorID) as mycount));\"\"\")\n",
    "print(authors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3\n",
    "We failed to write out this query succesfully, but this our attempt. It finds article ID's who share meta_keywordID's, and also shows the meta_keywordID they share\n",
    "### SQL\n",
    "``` mysql\n",
    "WITH tags_small AS (SELECT * FROM articlemeta_keywords WHERE articleid <= 500 and meta_keywordID > 0),\n",
    "     articles_small AS (SELECT DISTINCT articleid FROM tags_small)\n",
    "\tSELECT a1.meta_keywordID, a1.articleID AS a1, a2.articleID AS a2 FROM tags_small a1 JOIN tags_small a2 ON a1.articleID <> a2.articleID and a1.meta_keywordID = a2.meta_keywordID;\n",
    "```\n",
    "Running this query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed query and closed connection.\n",
      "[(12, 19, 20), (13, 19, 20), (14, 19, 20), (15, 19, 20), (16, 19, 20), (17, 19, 20), (18, 19, 20), (19, 19, 20), (12, 20, 19), (13, 20, 19), (14, 20, 19), (15, 20, 19), (16, 20, 19), (17, 20, 19), (18, 20, 19), (19, 20, 19), (27, 33, 99), (27, 33, 98), (37, 73, 138), (38, 73, 483), (38, 73, 138), (27, 98, 99), (27, 98, 33), (27, 99, 98), (27, 99, 33), (60, 109, 167), (61, 109, 167), (37, 138, 73), (38, 138, 483), (38, 138, 73), (64, 138, 483), (60, 167, 109), (61, 167, 109), (38, 483, 138), (38, 483, 73), (64, 483, 138)]\n"
     ]
    }
   ],
   "source": [
    "set_equi_join = execQuery(\"\"\"WITH tags_small AS (SELECT * FROM articlemeta_keywords WHERE articleid <= 500 and meta_keywordID > 0),\n",
    "     articles_small AS (SELECT DISTINCT articleid FROM tags_small)\n",
    "\tSELECT a1.meta_keywordID, a1.articleID AS a1, a2.articleID AS a2 FROM tags_small a1 JOIN tags_small a2 ON a1.articleID <> a2.articleID and a1.meta_keywordID = a2.meta_keywordID;\"\"\")\n",
    "print(set_equi_join)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 5\n",
    "## 5.1 Spider\n",
    "In order to scrape wikipedia for articels we have used the scrapy framework. Below is the code for our scrapy.Spider which scrapes the article obtaining the HTML code. Then "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
